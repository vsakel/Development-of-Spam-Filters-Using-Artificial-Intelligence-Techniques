{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3950,"status":"ok","timestamp":1698227841646,"user":{"displayName":"Basilis Sakellariou","userId":"01245548050423359889"},"user_tz":-180},"id":"CFTXItJkrKp-","outputId":"22d9b987-5091-488f-82c9-9c25e963e7f2"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# import libraries\n","\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","import numpy as np\n","import pandas as pd\n","import re\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.svm import SVC\n","from sklearn.metrics import accuracy_score, f1_score, balanced_accuracy_score\n","import nltk\n","from nltk.corpus import stopwords\n","nltk.download('stopwords')\n","from nltk.tokenize import word_tokenize\n","nltk.download('punkt')\n","from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rFPjPIAqrSid"},"outputs":[],"source":["# load the data\n","\n","sms = pd.read_csv('/content/drive/MyDrive/spam_detection/sms_translate.csv') # load spam dataset\n","\n","enron = pd.read_csv('/content/drive/MyDrive/spam_detection/enron_full.csv')\n","\n","youtube = pd.read_csv('/content/drive/MyDrive/spam_detection/youtube_translate.csv')"]},{"cell_type":"markdown","metadata":{"id":"c5lshF7OxbBu"},"source":["####gia na katharisw ta stopwords prepei na kanw prwta tokenization, opote kanw auto\n","####sth synexeia ta pernaw mesa apo to tfidf kai einai hdh tokenized"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A0ThAz88rWr3"},"outputs":[],"source":["# Prepare the dataset with tokenizer that separates words by \" \". also seperates the punctuation from the words if we keep them\n","# Secondly do some cleaning\n","\n","en_stop_words = stopwords.words('english')\n","gr_stop_words = stopwords.words('greek')\n","\n","def cleaning_en(text):\n","\n","    text = text.lower() #lowercasing\n","    tokens = word_tokenize(text) # tokenize\n","    tokens = [token for token in tokens if token not in en_stop_words] # remove stop words\n","\n","    return tokens\n","\n","def cleaning_gr(text):\n","\n","    text = text.lower()\n","    tokens = word_tokenize(text)\n","    # tokens = [token for token in tokens if token not in gr_stop_words] # remove stop words\n","\n","    return tokens\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ni7zix0NB7TR"},"outputs":[],"source":["# # preprocessing\n","# sms['tokenize_en'] = sms.Message.apply(cleaning_en)\n","# sms['tokenize_gr'] = sms.gtrans_el.apply(cleaning_gr)\n","\n","\n","enron['tokenize_en'] = enron.Message.apply(cleaning_en)\n","# enron['tokenize_gr'] = enron.gtrans_el.apply(cleaning_gr)\n","\n","\n","# twitter['tokenize_en'] = twitter.Message.apply(cleaning_en)\n","# twitter['tokenize_gr'] = twitter.gtrans_el.apply(cleaning_gr)\n","\n","\n","# youtube['tokenize_en'] = youtube.Message.apply(cleaning_en)\n","# youtube['tokenize_gr'] = youtube.gtrans_el.apply(cleaning_gr)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"al7B57kwyYl8"},"outputs":[],"source":["flag = 'en' # choose the language\n","data = enron # choose the dataset for training\n","name_data = 'enron'\n","\n","if flag == 'en':\n","\n","  # english data\n","  X = data.tokenize_en\n","  y = data.Category.values\n","\n","else:\n","\n","  # greek data\n","  X = data.tokenize_gr\n","  y = data.Category.values"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eAi2r6s_1WW8"},"outputs":[],"source":["Xtrain, Xtest,ytrain, ytest = train_test_split(X, y, random_state=56, test_size=0.2, stratify = y)\n","x_train, x_valid,y_train, y_valid = train_test_split(Xtrain, ytrain, random_state=56, test_size=0.25, stratify = ytrain)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z_XKO3Yi1LOH"},"outputs":[],"source":["# for tuning the hyperparameters\n","\n","Xtrain = x_train\n","Xtest = x_valid\n","ytest = y_valid\n","ytrain = y_train"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eE2QoCCz1P27","executionInfo":{"status":"ok","timestamp":1698228346115,"user_tz":-180,"elapsed":9163,"user":{"displayName":"Basilis Sakellariou","userId":"01245548050423359889"}},"outputId":"9a023e43-4427-48fd-b700-7d141f105f0c"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["features used:  1000\n"]}],"source":["# TFIDF vectorization\n","# our input is already tokenized which means the tokenized lists will be passed as it is to the vectorizer.\n","\n","vectorizer = TfidfVectorizer(max_features = 1000,lowercase=False,tokenizer=lambda x: x)\n","Xtrain_vec = vectorizer.fit_transform(Xtrain)\n","Xtest_vec = vectorizer.transform(Xtest)\n","\n","print('features used: ',Xtrain_vec.shape[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e4piUrrdzDsw","executionInfo":{"status":"ok","timestamp":1698228425569,"user_tz":-180,"elapsed":79469,"user":{"displayName":"Basilis Sakellariou","userId":"01245548050423359889"}},"outputId":"de993501-524f-4f07-fa0c-343ee4876972"},"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset used for training purpose is:  enron\n","Classifier:LogisticRegression(random_state=56, solver='liblinear') -  F1 macro:0.97\n","Classifier:DecisionTreeClassifier(random_state=56) -  F1 macro:0.9377\n","Classifier:SVC(random_state=56) -  F1 macro:0.9751\n","Classifier:RandomForestClassifier(n_jobs=-1, random_state=56) -  F1 macro:0.9743\n","Classifier:LogisticRegression(random_state=56, solver='liblinear') -  Accuracy:0.97\n","Classifier:DecisionTreeClassifier(random_state=56) -  Accuracy:0.9379\n","Classifier:SVC(random_state=56) -  Accuracy:0.9752\n","Classifier:RandomForestClassifier(n_jobs=-1, random_state=56) -  Accuracy:0.9743\n","Classifier:LogisticRegression(random_state=56, solver='liblinear') -  BalancedAccuracy:0.9705\n","Classifier:DecisionTreeClassifier(random_state=56) -  BalancedAccuracy:0.9382\n","Classifier:SVC(random_state=56) -  BalancedAccuracy:0.9755\n","Classifier:RandomForestClassifier(n_jobs=-1, random_state=56) -  BalancedAccuracy:0.9749\n"]}],"source":["# after vectorization\n","# train and evaluate different machine learning algorithms\n","# evaluation metrics accuracy, f1 macro, balanced accuracy\n","# Logistic Regression, Decision tree, SVM, Random Forest\n","# the ensemble method Random Forest decrease the propability that Decision tree has to overfit in training data\n","\n","\n","models = [LogisticRegression(solver='liblinear',random_state=56), DecisionTreeClassifier(random_state=56), SVC(random_state=56),\n","          RandomForestClassifier(n_estimators=100,n_jobs=-1,random_state=56)]\n","\n","f_measures = {}\n","acc = {}\n","balanced_acc = {}\n","\n","for clf in models:\n","  clf.fit(Xtrain_vec,ytrain)\n","  pred = clf.predict(Xtest_vec)\n","  key = f'{clf}'\n","  f_measures[key]=f1_score(ytest, pred, average='macro')\n","  acc[key] = accuracy_score(ytest,pred)\n","  balanced_acc[key] = balanced_accuracy_score(ytest,pred)\n","\n","\n","print(\"Dataset used for training purpose is: \",name_data)\n","for name,score in f_measures.items():\n","    print(\"Classifier:{} -  F1 macro:{}\".format(name,round(score,4)))\n","for name,score in acc.items():\n","    print(\"Classifier:{} -  Accuracy:{}\".format(name,round(score,4)))\n","for name,score in balanced_acc.items():\n","    print(\"Classifier:{} -  BalancedAccuracy:{}\".format(name,round(score,4)))"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}