{"cells":[{"cell_type":"markdown","metadata":{"id":"d1cBiud5lORJ"},"source":["Universal Filter"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16867,"status":"ok","timestamp":1699970051396,"user":{"displayName":"Basilis Sakellariou","userId":"01245548050423359889"},"user_tz":-120},"id":"1GXIYE0lRH8h","outputId":"f18d1f4e-7f8c-45e1-f101-ec1cac380201"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.35.0-py3-none-any.whl (7.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n","Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n","  Downloading huggingface_hub-0.19.1-py3-none-any.whl (311 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.1/311.1 kB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Collecting tokenizers<0.15,>=0.14 (from transformers)\n","  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m71.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n","Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n","  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n","Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n","Successfully installed huggingface-hub-0.17.3 safetensors-0.4.0 tokenizers-0.14.1 transformers-4.35.0\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"aTrt-6CYRIuA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699970146716,"user_tz":-120,"elapsed":95324,"user":{"displayName":"Basilis Sakellariou","userId":"01245548050423359889"}},"outputId":"f82ee892-41e1-4456-abe0-4e96f6f886f6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x791d05fa4f70>"]},"metadata":{},"execution_count":2}],"source":["# import libraries\n","import numpy as np\n","import torch\n","import matplotlib.pyplot as plt\n","from torch.utils.data import TensorDataset, DataLoader\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","import torch.nn.functional as F\n","from sklearn.metrics import accuracy_score, f1_score, balanced_accuracy_score, confusion_matrix, classification_report\n","from transformers import BertTokenizer, BertForSequenceClassification, AutoModelForSequenceClassification, AutoTokenizer, get_linear_schedule_with_warmup\n","from torch.optim import AdamW\n","from tqdm import tqdm\n","from google.colab import drive\n","drive.mount('/content/drive')\n","RANDOM_STATE = 56\n","torch.cuda.manual_seed_all(56)\n","torch.manual_seed(56)"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"w5vZFWDlRWmz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699970146717,"user_tz":-120,"elapsed":19,"user":{"displayName":"Basilis Sakellariou","userId":"01245548050423359889"}},"outputId":"4b183099-9942-4347-b8f3-14c3ea9b6353"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print('Using device:', device)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"jQxiaSMXRamE","executionInfo":{"status":"ok","timestamp":1699970148224,"user_tz":-120,"elapsed":1522,"user":{"displayName":"Basilis Sakellariou","userId":"01245548050423359889"}}},"outputs":[],"source":["# load the data\n","\n","data1 = pd.read_csv('/content/drive/MyDrive/spam_detection/sms_translate.csv')\n","\n","data2 = pd.read_csv('/content/drive/MyDrive/spam_detection/youtube_translate.csv')\n","\n","# evaluate on a custom dataset custom_test_setv2.csv\n","data = pd.read_csv('/content/drive/MyDrive/spam_detection/custom_test_set.csv') # 301 samples\n","\n","\n","language = 'gr'\n","\n","if language == 'en':\n","\n","  X1 = data1.Message\n","  Y1 = data1.Category.values\n","\n","  X2 = data2.Message\n","  Y2 = data2.Category.values\n","\n","  my_X = [data.Message, data.Message_el, data.gtrans_el]\n","  my_Y = [data.Category.values,data.Category.values,data.Category.values]\n","\n","\n","else:\n","\n","  X1 = data1.gtrans_el\n","  Y1 = data1.Category.values\n","\n","  X2 = data2.gtrans_el\n","  Y2 = data2.Category.values\n","\n","  my_X = [data.Message, data.Message_el, data.gtrans_el]\n","  my_Y = [data.Category.values,data.Category.values,data.Category.values]\n"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"At4RXPLQROOf","colab":{"base_uri":"https://localhost:8080/","height":232,"referenced_widgets":["ff69b387d30e4e01866c643683dd5b27","0dbeb3a1f68d499f963fcb0228fcbde3","e42858d59f0341efaba07cf93a7942c6","6bb8dbb092ef4b70b595d4cc75a23965","e461e6171cf048979d08760b31418202","0553edad1c554021ac5ded455cdfbf8a","bbb00669a6064f35873e383a2d86212b","43709858598443209f7f548285e5a213","da417e1d378f489188a8295eb0566a40","f0af8c04047a4421b3dd52310f97b430","8747e2eb0cba43d292f3a1493289bf44","d2a9374a06954c9d8ddc979ace51a884","716ffc0c2b2d4b909c207c7764d8f438","6fb994a86e6d457f80294fe8214ca7c5","edd243798ada44c0a3b5c7865bb4d8f7","4fff3d5924a440638e7fa7fd1c99cf40","902070c590c1486ba662c2db8d0d49a5","4c3ec719ae8245f79856d761f2692d42","3e248d8d0ae147e3b1cd1b5464dab9fe","3039c51f2cc04f5081268594358e7dc0","68d66059130d45e79aa75ca90c81fdba","cc57cb5a706d4fdb913d15946bfb8d6b","20c84b13e4ed4896979b1b50081af486","b05a3f9d03c941a78ce7df144a56c232","b4dcf8b29a004f55a1cf5dd0cfae8b89","3ece9ae467d1437a9d7082f5f40906c3","6aed27acd70f4d4bbe449d7a79c9c1c7","1e3cb771cc1f4ac2b5e43490e725834f","a1f097431bba42188f3e03d68f0c2280","f44bd08acd744df1a1d268bd28f92a77","fdd8b12ef35340c692e3803a0f353c85","da60f743b3274253a1caa1abb1043ba2","617873df3c5c4b4fb5bc444e30bff05a","d6c78c3bc5c445f091386c469d886561","ecbcdfae7f3541948a90edce3cb48bc9","9061c878536e49e690d3167e9567fb59","57c19c10fc734903a3444c4d4712b864","aa0dc3fed869424fa6e9d1e970523c0f","8b3049d4fb1a4f7e834dcabd279c7fe1","2703e5c98c9e48a2a0216cd068ce3886","2fcac24ef4ac439d874eb85491de7f0f","747763f7935d46e1b1f0405f2554e0de","5bbddad30430407d921da6c878044090","40d03c0cd58840ffb3be2cd83187f78c","5631fd03571e4068b4c14cce58844f9f","4fd9135f779f4c01bd4b2f206acf6734","6d2c5ac6802445f684d81d06de62e67a","551e139217514698841433668b6ce1bf","c91f052eabde4806826c361ca0646fda","355ed7e2ac14499e9c3e0713194f6823","36270673b1254b53892fc37df70ca7d0","5f15b0baeda340199fe1587b1d008cc0","6f7efdcd5a9146a0ac678b0e3dc14d53","199189be292f4ad4bdc41081eced882a","c648ffb7b6ea4ada9ea2392581052538"]},"executionInfo":{"status":"ok","timestamp":1699970179333,"user_tz":-120,"elapsed":31118,"user":{"displayName":"Basilis Sakellariou","userId":"01245548050423359889"}},"outputId":"ba8bba0d-d20c-4116-98b2-84ee0a9358c6"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff69b387d30e4e01866c643683dd5b27"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/459 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2a9374a06954c9d8ddc979ace51a884"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/530k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20c84b13e4ed4896979b1b50081af486"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6c78c3bc5c445f091386c469d886561"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/454M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5631fd03571e4068b4c14cce58844f9f"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlpaueb/bert-base-greek-uncased-v1 and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["if language == 'en':\n","\n","  tokenizer = BertTokenizer.from_pretrained('bert-base-uncased') # tokenizer\n","  model = BertForSequenceClassification.from_pretrained(\n","      \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n","      num_labels = 2, # The number of output labels--2 for binary classification.\n","  ).to(device)\n","\n","else:\n","\n","  # greek BERT for classification\n","  tokenizer = AutoTokenizer.from_pretrained(\"nlpaueb/bert-base-greek-uncased-v1\")\n","  model = AutoModelForSequenceClassification.from_pretrained(\"nlpaueb/bert-base-greek-uncased-v1\",num_labels=2).to(device)"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"5ZNlfrXNS4zC","executionInfo":{"status":"ok","timestamp":1699970207622,"user_tz":-120,"elapsed":1378,"user":{"displayName":"Basilis Sakellariou","userId":"01245548050423359889"}}},"outputs":[],"source":["def split_sets(weighted,X1,Y1,X2,Y2):\n","\n","    if weighted == 1:\n","\n","      length = len(X3) # length of youtube\n","\n","      # weighted X1\n","      spam_index = np.where(Y1==1)[0].tolist()\n","      ham_index = np.where(Y1==0)[0].tolist()\n","\n","      if length//2 > len(spam_index):\n","\n","        spam_index = spam_index\n","        ham_index = ham_index[0:(length-len(spam_index))]\n","        index = spam_index + ham_index\n","        X1 = X1[index]\n","        Y1 = Y1[index]\n","\n","      else:\n","\n","        spam_index = spam_index[0:length//2]\n","        ham_index = ham_index[0:length//2]\n","        index = spam_index + ham_index\n","        X1 = X1[index]\n","        Y1 = Y1[index]\n","\n","      # weighted X2\n","      spam_index = np.where(Y2==1)[0].tolist()\n","      ham_index = np.where(Y2==0)[0].tolist()\n","      if length/2 > len(spam_index):\n","        spam_index = spam_index\n","        ham_index = ham_index[0:(length-len(spam_index))]\n","        index = spam_index + ham_index\n","        X2 = X2[index]\n","        Y2 = Y2[index]\n","\n","      else:\n","\n","        spam_index = spam_index[0:length//2]\n","        ham_index = ham_index[0:length//2]\n","        index = spam_index + ham_index\n","        X2 = X2[index]\n","        Y2 = Y2[index]\n","\n","\n","\n","    Xtrain1, Xtest1,ytrain1, ytest1 = train_test_split(X1, Y1, random_state=RANDOM_STATE, test_size=0.2, stratify = Y1)\n","    x_train1, x_valid1 ,y_train1, y_valid1 = train_test_split(Xtrain1, ytrain1, random_state=RANDOM_STATE, test_size=0.25, stratify = ytrain1)\n","    Xtrain2, Xtest2,ytrain2, ytest2 = train_test_split(X2, Y2, random_state=RANDOM_STATE, test_size=0.2, stratify = Y2)\n","    x_train2, x_valid2 ,y_train2, y_valid2 = train_test_split(Xtrain2, ytrain2, random_state=RANDOM_STATE, test_size=0.25, stratify = ytrain2)\n","\n","\n","    # so Xtrain, ytrain has 80% from both sms datasets and youtube\n","    Xtrain = pd.concat([Xtrain1, Xtrain2], ignore_index = True)\n","    ytrain = np.concatenate((ytrain1, ytrain2))\n","\n","    # so x_train, y_train has 60% of both sms, youtube\n","    x_train = pd.concat([x_train1, x_train2], ignore_index = True)\n","    y_train = np.concatenate((y_train1, y_train2))\n","\n","    # so x_valid, y_valid has 20 % of both sms,youtube and used for evaluation via fune tuning\n","    x_valid = pd.concat([x_valid1, x_valid2], ignore_index = True)\n","    y_valid = np.concatenate((y_valid1, y_valid2))\n","\n","    # so test set has 20% from both sms and youtube datasets\n","    Xtest = pd.concat([Xtest1, Xtest2], ignore_index = True) # fusion of dataset\n","    ytest = np.concatenate((ytest1, ytest2))\n","\n","    return Xtrain,ytrain,x_train,y_train,x_valid,y_valid,Xtest,ytest,Xtest1,ytest1,Xtest2,ytest2\n","\n","\n","# weighted = 1-> take samples in the same size as youtube dataset, weighted samples of datasets\n","# weighted = 0 # 0 -> take whole datasets\n","\n","weighted = 0\n","# Xtest = fuse test set, Xtesti = evaluation test from dataset_i, i={1,2,3}\n","Xtrain, ytrain, x_train, y_train, x_valid, y_valid, Xtest, ytest, Xtest1, ytest1, Xtest2, ytest2 = split_sets(weighted,X1,Y1,X2,Y2)\n","\n","X_testing = [Xtest, Xtest1, Xtest2] + my_X\n","y_testing = [ytest, ytest1, ytest2] + my_Y\n","\n","sets = [\"fuse_test\", \"sms_test\",\"youtube_test\",\"my_test_en\",\"my_test_el\",\"my_test_el_machine_translated\"]"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"IVCrO3GYTEOr","executionInfo":{"status":"ok","timestamp":1699970211653,"user_tz":-120,"elapsed":775,"user":{"displayName":"Basilis Sakellariou","userId":"01245548050423359889"}}},"outputs":[],"source":["# encoding the input to be compatible with BERT model\n","# encoding train - test data and store them  representations in dataloaders\n","\n","def train_test_encoding(Xtrain,Xtest,ytrain,ytest,batch_size):\n","\n","  encoded_train = tokenizer.batch_encode_plus(Xtrain.tolist(), add_special_tokens=True, max_length = 128, padding='max_length' , truncation=True, return_tensors = 'pt')\n","  encoded_test = tokenizer.batch_encode_plus(Xtest.tolist(), add_special_tokens=True, max_length = 128, padding='max_length' , truncation=True, return_tensors = 'pt')\n","  input_ids_train = encoded_train['input_ids']\n","  attention_mask_train = encoded_train['attention_mask']\n","  labels_train = torch.tensor(ytrain)\n","  input_ids_test = encoded_test['input_ids']\n","  attention_mask_test = encoded_test['attention_mask']\n","  labels_test = torch.tensor(ytest)\n","\n","  # combine the training/testing inputs into a TensorDataset\n","  data_train = TensorDataset(input_ids_train, attention_mask_train, labels_train)\n","  data_test = TensorDataset(input_ids_test, attention_mask_test, labels_test)\n","\n","  dataloader_train = DataLoader(\n","              data_train,  # the training samples\n","              batch_size = batch_size, #traversing through the dataset with batch_size\n","              shuffle = True\n","          )\n","  # Shuffling the data after each epoch ensures that you will not be “stuck” with too many bad batches\n","\n","  dataloader_test = DataLoader(\n","              data_test, # The validation samples.\n","              batch_size = batch_size, # Evaluate with this batch size.\n","              shuffle = False\n","          )\n","\n","  return dataloader_train, dataloader_test"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"hDkUijBXTeZ6","executionInfo":{"status":"ok","timestamp":1699970212863,"user_tz":-120,"elapsed":3,"user":{"displayName":"Basilis Sakellariou","userId":"01245548050423359889"}}},"outputs":[],"source":["# get logits (tensors) and pass them through a softmax layer. Then turn them into predictions that stored in a numpy array\n","\n","def get_predictions(logits):\n"," prob_softmax = F.softmax(logits,dim=1)\n"," pred = np.array(np.argmax(prob_softmax,axis=1))\n"," return pred"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"y9hltIddCAox","executionInfo":{"status":"ok","timestamp":1699970215021,"user_tz":-120,"elapsed":3,"user":{"displayName":"Basilis Sakellariou","userId":"01245548050423359889"}}},"outputs":[],"source":["# compute the class weights\n","\n","# wj=n_samples / (n_classes * n_samplesj), for j=0,1 classes\n","\n","\n","def compute_class_weights(ytrain):\n","\n","  total_samples = len(ytrain)\n","  w0 = total_samples/(2*len([y for y in ytrain if y == 0]))\n","  w1 = total_samples/(2*len([y for y in ytrain if y == 1]))\n","\n","\n","  return w0,w1"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"btkSaATJTfBC","executionInfo":{"status":"ok","timestamp":1699970705634,"user_tz":-120,"elapsed":410,"user":{"displayName":"Basilis Sakellariou","userId":"01245548050423359889"}}},"outputs":[],"source":["# # RUN THIS ONLY ON VALIDATION PHASE TO FIND OPTIMAL NUMBER OF EPOCHS\n","\n","# batch_size = 32 # for training\n","# epochs = 4 # num of epochs to train\n","\n","# dataloader_train, dataloader_valid = train_test_encoding(x_train,x_valid,y_train,y_valid,batch_size)\n","# w0,w1 = compute_class_weights(y_train)\n","# weights = torch.tensor([w0, w1]).to(device)\n","\n","# # applying weight decay to all trainable parameters except bias and normalization layer weigths\n","# no_decay = ['bias', 'LayerNorm.weight']\n","# optimizer_grouped_parameters = [\n","#     {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n","#     {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n","# ]\n","# optimizer = AdamW(optimizer_grouped_parameters, lr=5e-5)\n","\n","# scheduler = get_linear_schedule_with_warmup(optimizer,num_warmup_steps=0*epochs*len(dataloader_train), num_training_steps = epochs*len(dataloader_train))\n","\n","\n","# # metrics per epoch\n","\n","# Loss_train = []\n","\n","\n","# f1_valid = []\n","# accuracy_valid = []\n","# Loss_valid = []\n","\n","\n","# for epoch in range(epochs):\n","\n","#   model.train() # set model to training mode\n","#   train_loss = 0 # accumulate loss for every batch per epoch\n","\n","#   # training loop\n","#   for step,batch in enumerate(tqdm(dataloader_train)):\n","\n","#     input_ids = batch[0].to(device)\n","#     attention_mask = batch[1].to(device)\n","#     labels = batch[2].to(device)\n","#     model.zero_grad() # clear gradients\n","#     outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n","#     # weighted loss for class imbalance\n","#     criterion = torch.nn.CrossEntropyLoss(weight=weights,reduction='mean')\n","#     batch_loss = criterion(outputs.logits, labels)\n","#     # batch_loss = outputs.loss # loss for the batch if we dont have weighted loss function\n","#     train_loss += batch_loss\n","#     batch_loss.backward()\n","#     # update parameters\n","#     optimizer.step()\n","#     # Update the learning rate.\n","#     scheduler.step()\n","\n","\n","\n","\n","\n","#   Loss_train.append(train_loss/len(dataloader_train))# compute the average loss for all the batches in epoch\n","\n","#   model.eval() # set model to evaluation mode\n","#   valid_loss = 0 # accumulate loss for every batch\n","#   all_logits = [] # store logits of every batch to pass them all into function get predictions and take the predictions overall\n","\n","#   # evaluation\n","#   for step,batch in enumerate(dataloader_valid):\n","\n","#     input_ids = batch[0].to(device)\n","#     attention_mask = batch[1].to(device)\n","#     labels = batch[2].to (device)\n","\n","#     with torch.no_grad():\n","#       outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n","#     batch_loss = outputs.loss # loss for the batch\n","#     all_logits.append(outputs.logits.cpu())\n","#     valid_loss += batch_loss\n","\n","#   all_logits = torch.cat(all_logits, dim=0)\n","#   pred = get_predictions(all_logits)\n","#   valid_loss = (valid_loss/len(dataloader_valid)) # compute the average loss for all the batches in epoch\n","\n","#    # validation metrics\n","#   Loss_valid.append(valid_loss)\n","#   accuracy_valid.append(accuracy_score(y_valid,pred))\n","#   f1_valid.append(f1_score(y_valid, pred, average='macro'))\n","\n","\n","\n","# # learning curves\n","\n","# epoch = [c for c in range(1,epochs+1)]\n","\n","# validation_loss = [loss.cpu() for loss in Loss_valid]\n","# training_loss = [tensor.detach().cpu() for tensor in Loss_train]\n","\n","# # plot learning curve\n","# plt.figure()\n","# plt.title('Loss')\n","# plt.plot(epoch,validation_loss,color='orange',label='validation')\n","# plt.plot(epoch,training_loss,color='blue',label='train')\n","# plt.xlabel('# of epochs')\n","# plt.xticks(epoch)\n","# plt.legend(['val_loss', 'loss'])\n","# plt.show()\n","\n","\n","# optimal_epochs = np.argmin(validation_loss) + 1\n","# print(\"optimal number of epochs found = \" +str(optimal_epochs)+\" with training Loss = \"+str(training_loss[optimal_epochs-1])+\" and validation Loss = \"+str(validation_loss[optimal_epochs-1]))"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"Rfv2Rp4EXNv2","executionInfo":{"status":"ok","timestamp":1699970223424,"user_tz":-120,"elapsed":4311,"user":{"displayName":"Basilis Sakellariou","userId":"01245548050423359889"}}},"outputs":[],"source":["# RUN THIS FOR TRAINING THE PRETRAINING MODEL IN ALL TRAIN DATASET\n","\n","# after we found the optimal hypeparameters\n","# train from the initial pretreained phase the model with all the train data = train + validation\n","# finally evaluate on test set\n","batch_size = 32\n","warm_up = 0.02\n","dataloader_train, dataloader_test = train_test_encoding(Xtrain,Xtest,ytrain,ytest,32) #Then we retrain it in all train data = train + validation\n","w0,w1 = compute_class_weights(ytrain)\n","weights = torch.tensor([w0, w1]).to(device)\n","\n","# reset the optimizer\n","no_decay = ['bias', 'LayerNorm.weight']\n","optimizer_grouped_parameters = [\n","    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n","    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n","]\n","optimizer = AdamW(optimizer_grouped_parameters, lr=4e-5)\n","\n","\n","if language == 'en':\n","\n","  optimal_epochs = 3 # for english for both weighted and no weighted fusion\n","\n","else:\n","\n","  optimal_epochs = 2 # no weighted fusion\n","\n","# new scheduler to train the model in all avaliable training data\n","scheduler = get_linear_schedule_with_warmup(optimizer,num_warmup_steps=warm_up*optimal_epochs*len(dataloader_train), num_training_steps = optimal_epochs*len(dataloader_train))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mFPULpePXTx7"},"outputs":[],"source":["model.train() # set model to training mode\n","\n","\n","for epoch in range(optimal_epochs):\n","\n","  # training loop\n","  for step,batch in enumerate(tqdm(dataloader_train)):\n","\n","    input_ids = batch[0].to(device)\n","    attention_mask = batch[1].to(device)\n","    labels = batch[2].to(device)\n","    model.zero_grad() # clear gradients\n","    outputs = model(input_ids, attention_mask=attention_mask, labels=labels) # forward pass\n","    # weighted loss for class imbalance\n","    criterion = torch.nn.CrossEntropyLoss(weight=weights,reduction='mean')\n","    batch_loss = criterion(outputs.logits, labels)\n","    # batch_loss = outputs.loss # loss for the batch if we dont have weighted loss function\n","    batch_loss.backward()\n","    # update parameters\n","    optimizer.step()\n","    # Update the learning rate.\n","    scheduler.step()\n","\n","\n","\n","\n","model.eval() # set model to evaluation mode\n","test_loss = 0 # accumulate loss for every batch\n","all_logits = [] # store logits of every batch to pass them all into function get predictions and take the predictions overall\n","\n","# evaluation of Xtest\n","for step,batch in enumerate(dataloader_test):\n","\n","  input_ids = batch[0].to(device)\n","  attention_mask = batch[1].to(device)\n","  labels = batch[2].to(device)\n","\n","  with torch.no_grad():\n","    outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n","  batch_loss = outputs.loss # loss for the batch\n","  all_logits.append(outputs.logits.cpu())\n","  test_loss += batch_loss\n","\n","\n","all_logits = torch.cat(all_logits, dim=0)\n","pred = get_predictions(all_logits)\n","test_loss = test_loss/len(dataloader_test) # compute the average loss for all the batches\n","print(\"results on test set: \"+str(sets[0]))\n","print(\"Loss is \"+str(test_loss))\n","print(\"Classification report:\\n\\n\"+str(classification_report(ytest,pred,target_names=['ham','spam'])))\n","print(\"accuracy is \"+str(round(accuracy_score(ytest,pred),4)))\n","print(\"f1 macro is \"+str(round(f1_score(ytest,pred,average='macro'),4)))\n","print(\"balanced accuracy is \"+str(round(balanced_accuracy_score(ytest,pred),4)))\n","print(\"confusion matrix\"+str(confusion_matrix(ytest, pred))+\"\\n\") # [[TN FP],[FN TP]]\n","\n","\n","predictions = []\n","\n","# evaluation of test dataset except Xtest\n","for i in range(1,len(X_testing)):\n","\n","  #encoding\n","  encoded_test = tokenizer.batch_encode_plus(X_testing[i].tolist(), add_special_tokens=True, max_length = 128, padding='max_length' , truncation=True, return_tensors = 'pt')\n","  input_ids_test = encoded_test['input_ids']\n","  attention_mask_test = encoded_test['attention_mask']\n","  labels_test = torch.tensor(y_testing[i])\n","\n","  data_test = TensorDataset(input_ids_test, attention_mask_test, labels_test)\n","  dataloader_test = DataLoader(\n","              data_test, # The validation samples.\n","              batch_size = 32, # Evaluate with this batch size.\n","              shuffle = False\n","          )\n","\n","  test_loss = 0 # accumulate loss for every batch\n","  all_logits = [] # store logits of every batch to pass them all into function get predictions and take the predictions overall\n","\n","  # evaluation\n","  for step,batch in enumerate(dataloader_test):\n","\n","    input_ids = batch[0].to(device)\n","    attention_mask = batch[1].to(device)\n","    labels = batch[2].to(device)\n","\n","    with torch.no_grad():\n","      outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n","    batch_loss = outputs.loss # loss for the batch\n","    all_logits.append(outputs.logits.cpu())\n","    test_loss += batch_loss\n","\n","\n","  all_logits = torch.cat(all_logits, dim=0)\n","  pred = get_predictions(all_logits)\n","  predictions.append(pred)\n","  test_loss = test_loss/len(dataloader_test) # compute the average loss for all the batches\n","  print(\"results on test set: \"+str(sets[i]))\n","  print(\"Loss is \"+str(test_loss))\n","  print(\"Classification report:\\n\\n\"+str(classification_report(y_testing[i],pred,target_names=['ham','spam'])))\n","  print(\"accuracy is \"+str(round(accuracy_score(y_testing[i],pred),4)))\n","  print(\"f1 macro is \"+str(round(f1_score(y_testing[i],pred,average='macro'),4)))\n","  print(\"balanced accuracy is \"+str(round(balanced_accuracy_score(y_testing[i],pred),4)))\n","  print(\"confusion matrix\"+str(confusion_matrix(y_testing[i], pred))+\"\\n\") # [[TN FP],[FN TP]]\n"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"t4PyhZb4QGty","executionInfo":{"status":"ok","timestamp":1699970698648,"user_tz":-120,"elapsed":346,"user":{"displayName":"Basilis Sakellariou","userId":"01245548050423359889"}}},"outputs":[],"source":["# save the fine tuned model\n","# torch.save(model.state_dict(),'/content/drive/My Drive/spam_detection/fine_tuned_models/Universal_filter_english.pth')"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"ff69b387d30e4e01866c643683dd5b27":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0dbeb3a1f68d499f963fcb0228fcbde3","IPY_MODEL_e42858d59f0341efaba07cf93a7942c6","IPY_MODEL_6bb8dbb092ef4b70b595d4cc75a23965"],"layout":"IPY_MODEL_e461e6171cf048979d08760b31418202"}},"0dbeb3a1f68d499f963fcb0228fcbde3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0553edad1c554021ac5ded455cdfbf8a","placeholder":"​","style":"IPY_MODEL_bbb00669a6064f35873e383a2d86212b","value":"Downloading (…)okenizer_config.json: 100%"}},"e42858d59f0341efaba07cf93a7942c6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_43709858598443209f7f548285e5a213","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_da417e1d378f489188a8295eb0566a40","value":2}},"6bb8dbb092ef4b70b595d4cc75a23965":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f0af8c04047a4421b3dd52310f97b430","placeholder":"​","style":"IPY_MODEL_8747e2eb0cba43d292f3a1493289bf44","value":" 2.00/2.00 [00:00&lt;00:00, 40.6B/s]"}},"e461e6171cf048979d08760b31418202":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0553edad1c554021ac5ded455cdfbf8a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bbb00669a6064f35873e383a2d86212b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"43709858598443209f7f548285e5a213":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"da417e1d378f489188a8295eb0566a40":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f0af8c04047a4421b3dd52310f97b430":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8747e2eb0cba43d292f3a1493289bf44":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d2a9374a06954c9d8ddc979ace51a884":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_716ffc0c2b2d4b909c207c7764d8f438","IPY_MODEL_6fb994a86e6d457f80294fe8214ca7c5","IPY_MODEL_edd243798ada44c0a3b5c7865bb4d8f7"],"layout":"IPY_MODEL_4fff3d5924a440638e7fa7fd1c99cf40"}},"716ffc0c2b2d4b909c207c7764d8f438":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_902070c590c1486ba662c2db8d0d49a5","placeholder":"​","style":"IPY_MODEL_4c3ec719ae8245f79856d761f2692d42","value":"Downloading (…)lve/main/config.json: 100%"}},"6fb994a86e6d457f80294fe8214ca7c5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e248d8d0ae147e3b1cd1b5464dab9fe","max":459,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3039c51f2cc04f5081268594358e7dc0","value":459}},"edd243798ada44c0a3b5c7865bb4d8f7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_68d66059130d45e79aa75ca90c81fdba","placeholder":"​","style":"IPY_MODEL_cc57cb5a706d4fdb913d15946bfb8d6b","value":" 459/459 [00:00&lt;00:00, 17.4kB/s]"}},"4fff3d5924a440638e7fa7fd1c99cf40":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"902070c590c1486ba662c2db8d0d49a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c3ec719ae8245f79856d761f2692d42":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3e248d8d0ae147e3b1cd1b5464dab9fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3039c51f2cc04f5081268594358e7dc0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"68d66059130d45e79aa75ca90c81fdba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc57cb5a706d4fdb913d15946bfb8d6b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"20c84b13e4ed4896979b1b50081af486":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b05a3f9d03c941a78ce7df144a56c232","IPY_MODEL_b4dcf8b29a004f55a1cf5dd0cfae8b89","IPY_MODEL_3ece9ae467d1437a9d7082f5f40906c3"],"layout":"IPY_MODEL_6aed27acd70f4d4bbe449d7a79c9c1c7"}},"b05a3f9d03c941a78ce7df144a56c232":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e3cb771cc1f4ac2b5e43490e725834f","placeholder":"​","style":"IPY_MODEL_a1f097431bba42188f3e03d68f0c2280","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"b4dcf8b29a004f55a1cf5dd0cfae8b89":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f44bd08acd744df1a1d268bd28f92a77","max":529930,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fdd8b12ef35340c692e3803a0f353c85","value":529930}},"3ece9ae467d1437a9d7082f5f40906c3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_da60f743b3274253a1caa1abb1043ba2","placeholder":"​","style":"IPY_MODEL_617873df3c5c4b4fb5bc444e30bff05a","value":" 530k/530k [00:00&lt;00:00, 8.19MB/s]"}},"6aed27acd70f4d4bbe449d7a79c9c1c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e3cb771cc1f4ac2b5e43490e725834f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a1f097431bba42188f3e03d68f0c2280":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f44bd08acd744df1a1d268bd28f92a77":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fdd8b12ef35340c692e3803a0f353c85":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"da60f743b3274253a1caa1abb1043ba2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"617873df3c5c4b4fb5bc444e30bff05a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d6c78c3bc5c445f091386c469d886561":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ecbcdfae7f3541948a90edce3cb48bc9","IPY_MODEL_9061c878536e49e690d3167e9567fb59","IPY_MODEL_57c19c10fc734903a3444c4d4712b864"],"layout":"IPY_MODEL_aa0dc3fed869424fa6e9d1e970523c0f"}},"ecbcdfae7f3541948a90edce3cb48bc9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8b3049d4fb1a4f7e834dcabd279c7fe1","placeholder":"​","style":"IPY_MODEL_2703e5c98c9e48a2a0216cd068ce3886","value":"Downloading (…)cial_tokens_map.json: 100%"}},"9061c878536e49e690d3167e9567fb59":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2fcac24ef4ac439d874eb85491de7f0f","max":112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_747763f7935d46e1b1f0405f2554e0de","value":112}},"57c19c10fc734903a3444c4d4712b864":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5bbddad30430407d921da6c878044090","placeholder":"​","style":"IPY_MODEL_40d03c0cd58840ffb3be2cd83187f78c","value":" 112/112 [00:00&lt;00:00, 6.55kB/s]"}},"aa0dc3fed869424fa6e9d1e970523c0f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b3049d4fb1a4f7e834dcabd279c7fe1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2703e5c98c9e48a2a0216cd068ce3886":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2fcac24ef4ac439d874eb85491de7f0f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"747763f7935d46e1b1f0405f2554e0de":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5bbddad30430407d921da6c878044090":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40d03c0cd58840ffb3be2cd83187f78c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5631fd03571e4068b4c14cce58844f9f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4fd9135f779f4c01bd4b2f206acf6734","IPY_MODEL_6d2c5ac6802445f684d81d06de62e67a","IPY_MODEL_551e139217514698841433668b6ce1bf"],"layout":"IPY_MODEL_c91f052eabde4806826c361ca0646fda"}},"4fd9135f779f4c01bd4b2f206acf6734":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_355ed7e2ac14499e9c3e0713194f6823","placeholder":"​","style":"IPY_MODEL_36270673b1254b53892fc37df70ca7d0","value":"Downloading pytorch_model.bin: 100%"}},"6d2c5ac6802445f684d81d06de62e67a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5f15b0baeda340199fe1587b1d008cc0","max":454248854,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6f7efdcd5a9146a0ac678b0e3dc14d53","value":454248854}},"551e139217514698841433668b6ce1bf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_199189be292f4ad4bdc41081eced882a","placeholder":"​","style":"IPY_MODEL_c648ffb7b6ea4ada9ea2392581052538","value":" 454M/454M [00:15&lt;00:00, 29.3MB/s]"}},"c91f052eabde4806826c361ca0646fda":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"355ed7e2ac14499e9c3e0713194f6823":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36270673b1254b53892fc37df70ca7d0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5f15b0baeda340199fe1587b1d008cc0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6f7efdcd5a9146a0ac678b0e3dc14d53":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"199189be292f4ad4bdc41081eced882a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c648ffb7b6ea4ada9ea2392581052538":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}