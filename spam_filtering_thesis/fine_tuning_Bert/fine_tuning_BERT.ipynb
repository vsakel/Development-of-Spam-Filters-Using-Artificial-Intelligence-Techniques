{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"78b9a9a719174632bace7a7ae4c43715":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_541d19f5fe6a45d9ad7de49627246e4d","IPY_MODEL_2b1a55cfe4274c78828f03311c0dd89b","IPY_MODEL_e595820de5b9473ab4fe7f8271473f99"],"layout":"IPY_MODEL_9e4c37409b7b4ac7b175633c21b34eb2"}},"541d19f5fe6a45d9ad7de49627246e4d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a45ad6af3d1b4a9cbee9a0c1abbfbec7","placeholder":"​","style":"IPY_MODEL_e26f20cb633c477f95698ab6e179d155","value":"Downloading (…)okenizer_config.json: 100%"}},"2b1a55cfe4274c78828f03311c0dd89b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_db1ad460d62d42d696147726c406697c","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0a16b3eea2284cd3b18e1f5dfe24ac2f","value":28}},"e595820de5b9473ab4fe7f8271473f99":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a4059010aeab4a648f1918957f00541a","placeholder":"​","style":"IPY_MODEL_87295bbfb7b143e9a3df0ebaaac158fc","value":" 28.0/28.0 [00:00&lt;00:00, 1.88kB/s]"}},"9e4c37409b7b4ac7b175633c21b34eb2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a45ad6af3d1b4a9cbee9a0c1abbfbec7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e26f20cb633c477f95698ab6e179d155":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"db1ad460d62d42d696147726c406697c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a16b3eea2284cd3b18e1f5dfe24ac2f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a4059010aeab4a648f1918957f00541a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"87295bbfb7b143e9a3df0ebaaac158fc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"808b63a925c14b78aa279b65136d9079":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d26e5493628a44beb060d40514c37d46","IPY_MODEL_ca254b5fb97f421ea881455b0c15c9a1","IPY_MODEL_8abdfd29f78e49d282bce55c32509c6c"],"layout":"IPY_MODEL_b9d2866fec61408ca62d587c51eb6670"}},"d26e5493628a44beb060d40514c37d46":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ecbe675ab9254f3bb1d6d69d0a19d423","placeholder":"​","style":"IPY_MODEL_e115a64be61544958f1c7bc4a96658d3","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"ca254b5fb97f421ea881455b0c15c9a1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f3a19aea9bc42ba8bd4ee1c7537aea9","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ae3536ada070486ca79a9305056e1c84","value":231508}},"8abdfd29f78e49d282bce55c32509c6c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0bb61b4b4520407ea68eb23c46e03d79","placeholder":"​","style":"IPY_MODEL_0322d130f2aa479c8c9729b81d727a31","value":" 232k/232k [00:00&lt;00:00, 2.74MB/s]"}},"b9d2866fec61408ca62d587c51eb6670":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ecbe675ab9254f3bb1d6d69d0a19d423":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e115a64be61544958f1c7bc4a96658d3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8f3a19aea9bc42ba8bd4ee1c7537aea9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae3536ada070486ca79a9305056e1c84":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0bb61b4b4520407ea68eb23c46e03d79":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0322d130f2aa479c8c9729b81d727a31":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a197abd4397f4bd6bb435605484d34c3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_63a6dfadce2147a087bfaa060a7b122b","IPY_MODEL_c3075b3bb25342f68580492131677ed6","IPY_MODEL_57821ba77bf7453dbd47afc190af4abd"],"layout":"IPY_MODEL_587698034a644105984d09f6565f03c8"}},"63a6dfadce2147a087bfaa060a7b122b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc7f2f18316143408bb2238d86bfc794","placeholder":"​","style":"IPY_MODEL_f5d8e8be42b64cb28959e946cc2e96ce","value":"Downloading (…)/main/tokenizer.json: 100%"}},"c3075b3bb25342f68580492131677ed6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_80b39f7cb6c84803988ec86e61d1e08d","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3498cea3d3774639858cb1ba9acccc91","value":466062}},"57821ba77bf7453dbd47afc190af4abd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_278807c55b024009b05aa4896511ece5","placeholder":"​","style":"IPY_MODEL_437c01a749e640ff8c24a7c1c172b3aa","value":" 466k/466k [00:00&lt;00:00, 3.44MB/s]"}},"587698034a644105984d09f6565f03c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc7f2f18316143408bb2238d86bfc794":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5d8e8be42b64cb28959e946cc2e96ce":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"80b39f7cb6c84803988ec86e61d1e08d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3498cea3d3774639858cb1ba9acccc91":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"278807c55b024009b05aa4896511ece5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"437c01a749e640ff8c24a7c1c172b3aa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3d46a01161a14ab19be46aaa8eb28958":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ed2eba34691d4e949322728ed6c7ea61","IPY_MODEL_9fcb9b9e3f8643faab9946b5fe19f2e5","IPY_MODEL_9dadecfb26234fb5b631cacfe0189a4a"],"layout":"IPY_MODEL_239007983b414b35ac8ef4e3b306d66b"}},"ed2eba34691d4e949322728ed6c7ea61":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_17ce1853d7ee4d8ba1e6c1c32ef2c67e","placeholder":"​","style":"IPY_MODEL_ed9ba21d697e47ea929be0abcba91597","value":"Downloading (…)lve/main/config.json: 100%"}},"9fcb9b9e3f8643faab9946b5fe19f2e5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e680d89e869042eda6da4b0d55d092fb","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_230f474ccf90408396a9c26bcd4f6c1d","value":570}},"9dadecfb26234fb5b631cacfe0189a4a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5a18257cc65e45e78cf717ca1276e280","placeholder":"​","style":"IPY_MODEL_81c21388063f4818ad2242b492c708fa","value":" 570/570 [00:00&lt;00:00, 17.2kB/s]"}},"239007983b414b35ac8ef4e3b306d66b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17ce1853d7ee4d8ba1e6c1c32ef2c67e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed9ba21d697e47ea929be0abcba91597":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e680d89e869042eda6da4b0d55d092fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"230f474ccf90408396a9c26bcd4f6c1d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5a18257cc65e45e78cf717ca1276e280":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81c21388063f4818ad2242b492c708fa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3b46e5d528a34246a948869818791f50":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bf5705fe01c24f73beea1157a6d33d8a","IPY_MODEL_b9ec8625f44e40608e3d976992540a5f","IPY_MODEL_23a1ba7a6da54bbfa7fc89abba22b1c7"],"layout":"IPY_MODEL_fbddde21ce0842de81be9e9a5a710bdd"}},"bf5705fe01c24f73beea1157a6d33d8a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_43c93c47f55c40f08709109807c83f87","placeholder":"​","style":"IPY_MODEL_2d68c22088fa44779961fc0924b846b6","value":"Downloading model.safetensors: 100%"}},"b9ec8625f44e40608e3d976992540a5f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_92b8b3e1f09b4259bbe68ed9e3fcd0ae","max":440449768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_65742213f1874fdd819c1b9ca88fa82c","value":440449768}},"23a1ba7a6da54bbfa7fc89abba22b1c7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b8de29d096e047e8996d3460cc943980","placeholder":"​","style":"IPY_MODEL_afe2db3c04694348912595350e754841","value":" 440M/440M [00:07&lt;00:00, 88.7MB/s]"}},"fbddde21ce0842de81be9e9a5a710bdd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"43c93c47f55c40f08709109807c83f87":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d68c22088fa44779961fc0924b846b6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"92b8b3e1f09b4259bbe68ed9e3fcd0ae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"65742213f1874fdd819c1b9ca88fa82c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b8de29d096e047e8996d3460cc943980":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"afe2db3c04694348912595350e754841":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["fine tuning BERT on each dataset"],"metadata":{"id":"swTBxq8TATwx"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"2keKfZ7xsJD6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699116599297,"user_tz":-120,"elapsed":16246,"user":{"displayName":"Basilis Sakellariou","userId":"01245548050423359889"}},"outputId":"39144a8a-7815-4541-a023-997188c4bce0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.35.0-py3-none-any.whl (7.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n","Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n","  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Collecting tokenizers<0.15,>=0.14 (from transformers)\n","  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n","Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n","  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n","Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n","Successfully installed huggingface-hub-0.17.3 safetensors-0.4.0 tokenizers-0.14.1 transformers-4.35.0\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XuBwhxawsOoC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699116716653,"user_tz":-120,"elapsed":117360,"user":{"displayName":"Basilis Sakellariou","userId":"01245548050423359889"}},"outputId":"a446e098-16b0-4bdd-cf3a-d53e5098e83a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x78c3bc2a1070>"]},"metadata":{},"execution_count":2}],"source":["# import libraries\n","import numpy as np\n","import torch\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","from torch.utils.data import TensorDataset, DataLoader\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","import torch.nn.functional as F\n","from sklearn.metrics import accuracy_score, f1_score, balanced_accuracy_score, confusion_matrix, classification_report\n","from transformers import BertTokenizer, BertForSequenceClassification, AutoModelForSequenceClassification, AutoConfig, AutoTokenizer, BertConfig, get_linear_schedule_with_warmup\n","from torch.optim import AdamW\n","from google.colab import drive\n","drive.mount('/content/drive')\n","torch.cuda.manual_seed_all(56)\n","torch.manual_seed(56)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wSBhdMZtsQdD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699116716654,"user_tz":-120,"elapsed":8,"user":{"displayName":"Basilis Sakellariou","userId":"01245548050423359889"}},"outputId":"e54b5192-5ca4-4ea3-b4c9-2314d2a57a79"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# to take advantage of gpu acceleration on training\n","print('Using device:', device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r9hTX3OKtTRF"},"outputs":[],"source":["# load the data\n","\n","# sms = pd.read_csv('/content/drive/MyDrive/spam_detection/sms_translate.csv') # load sms spam dataset\n","\n","# enron = pd.read_csv('/content/drive/MyDrive/spam_detection/enron_full.csv')\n","\n","youtube = pd.read_csv('/content/drive/MyDrive/spam_detection/youtube_translate.csv')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6jcHUXXwxf0f"},"outputs":[],"source":["# train-test split\n","\n","language = 'en' # language of message\n","data = youtube # dataset\n","\n","if language == 'en':\n","\n","  X = data.Message\n","  y = data.Category.values\n","\n","else:\n","\n","  X = data.gtrans_el\n","  y = data.Category.values\n","\n","\n","# split into 60:20:20\n","Xtrain, Xtest,ytrain, ytest = train_test_split(X, y, random_state=56, test_size=0.2, stratify = y)\n","x_train, x_valid ,y_train, y_valid = train_test_split(Xtrain, ytrain, random_state=56, test_size=0.25, stratify = ytrain)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3ZNZCAbEB1U0","colab":{"base_uri":"https://localhost:8080/","height":232,"referenced_widgets":["78b9a9a719174632bace7a7ae4c43715","541d19f5fe6a45d9ad7de49627246e4d","2b1a55cfe4274c78828f03311c0dd89b","e595820de5b9473ab4fe7f8271473f99","9e4c37409b7b4ac7b175633c21b34eb2","a45ad6af3d1b4a9cbee9a0c1abbfbec7","e26f20cb633c477f95698ab6e179d155","db1ad460d62d42d696147726c406697c","0a16b3eea2284cd3b18e1f5dfe24ac2f","a4059010aeab4a648f1918957f00541a","87295bbfb7b143e9a3df0ebaaac158fc","808b63a925c14b78aa279b65136d9079","d26e5493628a44beb060d40514c37d46","ca254b5fb97f421ea881455b0c15c9a1","8abdfd29f78e49d282bce55c32509c6c","b9d2866fec61408ca62d587c51eb6670","ecbe675ab9254f3bb1d6d69d0a19d423","e115a64be61544958f1c7bc4a96658d3","8f3a19aea9bc42ba8bd4ee1c7537aea9","ae3536ada070486ca79a9305056e1c84","0bb61b4b4520407ea68eb23c46e03d79","0322d130f2aa479c8c9729b81d727a31","a197abd4397f4bd6bb435605484d34c3","63a6dfadce2147a087bfaa060a7b122b","c3075b3bb25342f68580492131677ed6","57821ba77bf7453dbd47afc190af4abd","587698034a644105984d09f6565f03c8","bc7f2f18316143408bb2238d86bfc794","f5d8e8be42b64cb28959e946cc2e96ce","80b39f7cb6c84803988ec86e61d1e08d","3498cea3d3774639858cb1ba9acccc91","278807c55b024009b05aa4896511ece5","437c01a749e640ff8c24a7c1c172b3aa","3d46a01161a14ab19be46aaa8eb28958","ed2eba34691d4e949322728ed6c7ea61","9fcb9b9e3f8643faab9946b5fe19f2e5","9dadecfb26234fb5b631cacfe0189a4a","239007983b414b35ac8ef4e3b306d66b","17ce1853d7ee4d8ba1e6c1c32ef2c67e","ed9ba21d697e47ea929be0abcba91597","e680d89e869042eda6da4b0d55d092fb","230f474ccf90408396a9c26bcd4f6c1d","5a18257cc65e45e78cf717ca1276e280","81c21388063f4818ad2242b492c708fa","3b46e5d528a34246a948869818791f50","bf5705fe01c24f73beea1157a6d33d8a","b9ec8625f44e40608e3d976992540a5f","23a1ba7a6da54bbfa7fc89abba22b1c7","fbddde21ce0842de81be9e9a5a710bdd","43c93c47f55c40f08709109807c83f87","2d68c22088fa44779961fc0924b846b6","92b8b3e1f09b4259bbe68ed9e3fcd0ae","65742213f1874fdd819c1b9ca88fa82c","b8de29d096e047e8996d3460cc943980","afe2db3c04694348912595350e754841"]},"executionInfo":{"status":"ok","timestamp":1699116737858,"user_tz":-120,"elapsed":20312,"user":{"displayName":"Basilis Sakellariou","userId":"01245548050423359889"}},"outputId":"2ca97781-280b-4e4d-a986-d0bdfa1a0060"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78b9a9a719174632bace7a7ae4c43715"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"808b63a925c14b78aa279b65136d9079"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a197abd4397f4bd6bb435605484d34c3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d46a01161a14ab19be46aaa8eb28958"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b46e5d528a34246a948869818791f50"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["if language == 'en':\n","\n","  tokenizer = BertTokenizer.from_pretrained('bert-base-uncased') # tokenizer\n","  model = BertForSequenceClassification.from_pretrained(\n","      \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n","      num_labels = 2, # The number of output labels--2 for binary classification.\n","      output_attentions = False, # Whether the model returns attentions weights.\n","      output_hidden_states = False, # Whether the model returns all hidden-states.\n","  ).to(device)\n","\n","else:\n","\n","  # greek BERT for classification\n","  tokenizer = AutoTokenizer.from_pretrained(\"nlpaueb/bert-base-greek-uncased-v1\")\n","  model = AutoModelForSequenceClassification.from_pretrained(\"nlpaueb/bert-base-greek-uncased-v1\",num_labels=2).to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TKQDtsgNXLS9"},"outputs":[],"source":["# encoding the input to be compatible with BERT model\n","# encoding train - test data and store them  representations in dataloaders\n","\n","def train_test(Xtrain,Xtest,ytrain,ytest,batch_size):\n","\n","  encoded_train = tokenizer.batch_encode_plus(Xtrain.tolist(), add_special_tokens=True, max_length = 50, padding='max_length' , truncation=True, return_tensors = 'pt')\n","  encoded_test = tokenizer.batch_encode_plus(Xtest.tolist(), add_special_tokens=True, max_length = 50, padding='max_length' , truncation=True, return_tensors = 'pt')\n","  input_ids_train = encoded_train['input_ids']\n","  attention_mask_train = encoded_train['attention_mask']\n","  labels_train = torch.tensor(ytrain)\n","  input_ids_test = encoded_test['input_ids']\n","  attention_mask_test = encoded_test['attention_mask']\n","  labels_test = torch.tensor(ytest)\n","\n","  # combine the training/testing inputs into a TensorDataset\n","  data_train = TensorDataset(input_ids_train, attention_mask_train, labels_train)\n","  data_test = TensorDataset(input_ids_test, attention_mask_test, labels_test)\n","\n","  dataloader_train = DataLoader(\n","              data_train,  # the training samples\n","              batch_size = batch_size, #traversing through the dataset with batch_size\n","              shuffle = True\n","          )\n","  # Shuffling the data after each epoch ensures that you will not be “stuck” with too many bad batches\n","\n","  dataloader_test = DataLoader(\n","              data_test, # The validation samples.\n","              batch_size = batch_size, # Evaluate with this batch size.\n","              shuffle = False\n","          )\n","\n","  return dataloader_train, dataloader_test\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qEc7t4BYfU-0"},"outputs":[],"source":["# get logits (tensors) and pass them through a softmax layer. Then turn them into predictions that stored in a numpy array\n","\n","def get_predictions(logits):\n"," prob_softmax = F.softmax(logits,dim=1)\n"," pred = np.array(np.argmax(prob_softmax,axis=1))\n"," return pred\n"]},{"cell_type":"code","source":["# compute the class weights\n","\n","# wj=n_samples / (n_classes * n_samplesj), for j=0,1 classes\n","\n","\n","def compute_class_weights(ytrain):\n","\n","  total_samples = len(ytrain)\n","  w0 = total_samples/(2*len([y for y in ytrain if y == 0]))\n","  w1 = total_samples/(2*len([y for y in ytrain if y == 1]))\n","\n","\n","  return w0,w1"],"metadata":{"id":"o8MD8_zot3wb"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QTmIAR0qtayG"},"outputs":[],"source":["# # fine tuning hyperparameters: num_epochs and learning_rate by evaluating on validation set\n","\n","# batch_size = 32 # for training\n","# epochs = 4 # num of epochs to train\n","# warm_up = 0.02\n","\n","# dataloader_train, dataloader_valid = train_test(x_train,x_valid,y_train,y_valid,batch_size)\n","# w0,w1 = compute_class_weights(y_train)\n","# weights = torch.tensor([w0, w1]).to(device)\n","\n","# # define optimizer and scheduler\n","\n","# # applying weight decay to all trainable parameters except bias and normalization layer weigths\n","# no_decay = ['bias', 'LayerNorm.weight']\n","# optimizer_grouped_parameters = [\n","#     {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n","#     {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n","# ]\n","# optimizer = AdamW(optimizer_grouped_parameters, lr=4e-5)\n","\n","# scheduler = get_linear_schedule_with_warmup(optimizer,num_warmup_steps=warm_up*epochs*len(dataloader_train), num_training_steps = epochs*len(dataloader_train))\n","\n","\n","# # metrics per epoch\n","\n","# Loss_train = []\n","\n","\n","# f1_valid = []\n","# accuracy_valid = []\n","# Loss_valid = []\n","\n","\n","# for epoch in range(epochs):\n","\n","#   model.train() # set model to training mode\n","#   train_loss = 0 # accumulate loss for every batch per epoch\n","\n","#   # training loop\n","#   for step,batch in enumerate(tqdm(dataloader_train)):\n","\n","#     input_ids = batch[0].to(device)\n","#     attention_mask = batch[1].to(device)\n","#     labels = batch[2].to(device)\n","#     model.zero_grad() # clear gradients\n","#     outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n","#     # # weighted loss for class imbalance\n","#     criterion = torch.nn.CrossEntropyLoss(weight=weights,reduction='mean')\n","#     batch_loss = criterion(outputs.logits, labels)\n","#     # batch_loss = outputs.loss # loss for the batch if we dont have weighted loss function\n","#     train_loss += batch_loss\n","#     batch_loss.backward()\n","#     # update parameters\n","#     optimizer.step()\n","#     # Update the learning rate.\n","#     scheduler.step()\n","\n","\n","#   Loss_train.append(train_loss/len(dataloader_train))# compute the average loss for all the batches in epoch\n","\n","#   model.eval() # set model to evaluation mode\n","#   valid_loss = 0 # accumulate loss for every batch\n","#   all_logits = [] # store logits of every batch to pass them all into function get predictions and take the predictions overall\n","\n","#   # evaluation\n","#   for step,batch in enumerate(dataloader_valid):\n","\n","#     input_ids = batch[0].to(device)\n","#     attention_mask = batch[1].to(device)\n","#     labels = batch[2].to(device)\n","\n","#     with torch.no_grad():\n","#       outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n","#     batch_loss = outputs.loss # loss for the batch\n","#     all_logits.append(outputs.logits.cpu())\n","#     valid_loss += batch_loss\n","#     # del  input_ids, attention_mask, labels, outputs\n","\n","#   all_logits = torch.cat(all_logits, dim=0)\n","#   pred = get_predictions(all_logits)\n","#   valid_loss = (valid_loss/len(dataloader_valid)) # compute the average loss for all the batches in epoch\n","\n","#    # validation metrics\n","#   Loss_valid.append(valid_loss)\n","#   accuracy_valid.append(accuracy_score(y_valid,pred))\n","#   f1_valid.append(f1_score(y_valid, pred, average='macro'))\n","\n","\n","\n","# # learning curves\n","\n","# epoch = [c for c in range(1,epochs+1)]\n","\n","# validation_loss = [loss.cpu() for loss in Loss_valid]\n","# training_loss = [tensor.detach().cpu() for tensor in Loss_train]\n","\n","# # plot learning curve\n","# plt.figure()\n","# plt.title('Loss')\n","# plt.plot(epoch,validation_loss,color='orange',label='validation')\n","# plt.plot(epoch,training_loss,color='blue',label='train')\n","# plt.xlabel('# of epochs')\n","# plt.xticks(epoch)\n","# plt.legend(['val_loss', 'loss'])\n","# plt.show()\n","\n","# optimal_epochs = np.argmin(validation_loss) + 1\n","# print(\"optimal number of epochs found = \" +str(optimal_epochs)+\" with training Loss = \"+str(training_loss[optimal_epochs-1])+\" and validation Loss = \"+str(validation_loss[optimal_epochs-1]))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oZ8rgIiduGuu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699116775692,"user_tz":-120,"elapsed":37849,"user":{"displayName":"Basilis Sakellariou","userId":"01245548050423359889"}},"outputId":"3ca0592d-880b-4e10-b38a-16f4d5e6ed0d"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 42/42 [00:13<00:00,  3.03it/s]\n","100%|██████████| 42/42 [00:10<00:00,  4.10it/s]\n","100%|██████████| 42/42 [00:10<00:00,  4.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["results:\n","Loss is tensor(0.1971, device='cuda:0')\n","Classification report:\n","\n","              precision    recall  f1-score   support\n","\n","         ham       0.93      0.97      0.95       176\n","        spam       0.96      0.92      0.94       153\n","\n","    accuracy                           0.95       329\n","   macro avg       0.95      0.94      0.94       329\n","weighted avg       0.95      0.95      0.95       329\n","\n","accuracy is 0.9453\n","balanced accuracy is 0.9437\n","f1 macro is 0.9449\n","\n","confusion matrix[[170   6]\n"," [ 12 141]]\n","\n","\n"]}],"source":["# after we found the optimal epochs and learning rate values\n","# we reset the model in pretrained state. Then we retrain it in all train data = train + validation\n","# finally evaluate on test set\n","\n","optimal_epochs = 3\n","batch_size = 32\n","\n","dataloader_train, dataloader_test = train_test(Xtrain,Xtest,ytrain,ytest,batch_size)\n","w0,w1 = compute_class_weights(ytrain)\n","weights = torch.tensor([w0, w1]).to(device)\n","\n","# define optimizer and scheduler\n","\n","# applying weight decay to all trainable parameters except bias and normalization layer weigths\n","no_decay = ['bias', 'LayerNorm.weight']\n","optimizer_grouped_parameters = [\n","    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n","    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n","]\n","optimizer = AdamW(optimizer_grouped_parameters, lr=4e-5)\n","\n","\n","# new scheduler to train the model in all avaliable training data\n","scheduler = get_linear_schedule_with_warmup(optimizer,num_warmup_steps=0*optimal_epochs*len(dataloader_train), num_training_steps = optimal_epochs*len(dataloader_train))\n","\n","\n","model.train() # set model to training mode\n","\n","for epoch in range(optimal_epochs):\n","\n","  # training loop\n","  for step,batch in enumerate(tqdm(dataloader_train)):\n","\n","    input_ids = batch[0].to(device)\n","    attention_mask = batch[1].to(device)\n","    labels = batch[2].to(device)\n","    model.zero_grad() # clear gradients\n","    outputs = model(input_ids, attention_mask=attention_mask, labels=labels) # forward pass\n","    ## weighted loss for class imbalance\n","    # criterion = torch.nn.CrossEntropyLoss(weight=weights,reduction='mean')\n","    # batch_loss = criterion(outputs.logits, labels)\n","    batch_loss = outputs.loss # loss for the batch if we dont have weighted loss function\n","    batch_loss.backward() # compute gradients of cost function (Cross Entropy Loss) wih respect to all parameters\n","    # update parameters\n","    optimizer.step()\n","    # Update the learning rate.\n","    scheduler.step()\n","\n","\n","\n","# evaluation of model\n","\n","model.eval() # set model to evaluation mode\n","test_loss = 0 # accumulate loss for every batch\n","all_logits = [] # store logits of every batch to pass them all into function get predictions and take the predictions overall\n","\n","# evaluation\n","for step,batch in enumerate(dataloader_test):\n","\n","  input_ids = batch[0].to(device)\n","  attention_mask = batch[1].to(device)\n","  labels = batch[2].to(device)\n","\n","  with torch.no_grad():\n","    outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n","  batch_loss = outputs.loss # loss for the batch\n","  all_logits.append(outputs.logits.cpu())\n","  test_loss += batch_loss\n","\n","\n","all_logits = torch.cat(all_logits, dim=0)\n","pred = get_predictions(all_logits)\n","test_loss = test_loss/len(dataloader_test) # compute the average loss for all the batches\n","print(\"results:\")\n","print(\"Loss is \"+str(test_loss))\n","print(\"Classification report:\\n\\n\"+str(classification_report(ytest,pred,target_names=['ham','spam'])))\n","print(\"accuracy is \"+str(round(accuracy_score(ytest,pred),4)))\n","print(\"balanced accuracy is \"+str(round(balanced_accuracy_score(ytest,pred),4)))\n","print(\"f1 macro is \"+str(round(f1_score(ytest, pred, average='macro'),4))+\"\\n\")\n","print(\"confusion matrix\"+str(confusion_matrix(ytest, pred))+\"\\n\\n\") # [[TN FP],[FN TP]]"]},{"cell_type":"code","source":["# torch.save(model.state_dict(),'/content/drive/My Drive/spam_detection/fine_tuned_models/Greek_BERT_youtube.pth')"],"metadata":{"id":"Py70_IpeTA06"},"execution_count":null,"outputs":[]}]}