{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["in this notebook we use pipeline of 3 thematic filters,\n","\n","we want to see if we can achieve better results in our custom dataset"],"metadata":{"id":"QbsUM-R2RXln"}},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mFSkYYOzRxSL","executionInfo":{"status":"ok","timestamp":1700261897552,"user_tz":-120,"elapsed":9127,"user":{"displayName":"Basilis Sakellariou","userId":"01245548050423359889"}},"outputId":"f55d6cda-771c-4500-ad2e-b6838f67546b"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"]}]},{"cell_type":"code","source":["# import libraries\n","import numpy as np\n","import torch\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","from torch.utils.data import TensorDataset, DataLoader\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","import torch.nn.functional as F\n","from sklearn.metrics import accuracy_score, f1_score, balanced_accuracy_score, confusion_matrix, classification_report\n","from transformers import BertTokenizer, BertForSequenceClassification, AutoModelForSequenceClassification, AutoConfig, AutoTokenizer, BertConfig, get_linear_schedule_with_warmup\n","from torch.optim import AdamW\n","from google.colab import drive\n","from google.colab import files\n","drive.mount('/content/drive')\n","torch.cuda.manual_seed_all(56)\n","torch.manual_seed(56)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V5d6ImiwR9sg","executionInfo":{"status":"ok","timestamp":1700261899560,"user_tz":-120,"elapsed":2016,"user":{"displayName":"Basilis Sakellariou","userId":"01245548050423359889"}},"outputId":"704b76ef-d787-4adb-a178-72af9db4fc86"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]},{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7f40e675e4b0>"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# to take advantage of gpu acceleration on training\n","print('Using device:', device)"],"metadata":{"id":"cLCUWx8BSAqR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700261899561,"user_tz":-120,"elapsed":8,"user":{"displayName":"Basilis Sakellariou","userId":"01245548050423359889"}},"outputId":"e6881aa5-a71b-4954-e097-cf5646ccef7a"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]}]},{"cell_type":"code","source":["# load the data\n","\n","my_data = pd.read_csv('/content/drive/MyDrive/spam_detection/custom_test_set.csv') # new custom dataset with 301 samples\n"],"metadata":{"id":"ET1Fd1mGSCbb","executionInfo":{"status":"ok","timestamp":1700261899561,"user_tz":-120,"elapsed":5,"user":{"displayName":"Basilis Sakellariou","userId":"01245548050423359889"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["language = 'gr' # language of message\n","\n","\n","if language == 'en':\n","\n","  tokenizer = BertTokenizer.from_pretrained('bert-base-uncased') # tokenizer\n","  social_prom_filter = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",num_labels = 2).to(device)\n","  advertisement_filter = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",num_labels = 2).to(device)\n","  phising_filter = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",num_labels = 2).to(device)\n","\n","\n","  # load the fine tuned thematic filters\n","  social_prom_filter.load_state_dict(torch.load('/content/drive/My Drive/spam_detection/thematic_filtering/BERT_social_promotion_filter.pth')) # social promotion filter\n","  social_prom_filter.eval()\n","  advertisement_filter.load_state_dict(torch.load('/content/drive/My Drive/spam_detection/thematic_filtering/BERT_advertisement_filter.pth')) # advertisement filter\n","  advertisement_filter.eval()\n","  phising_filter.load_state_dict(torch.load('/content/drive/My Drive/spam_detection/thematic_filtering/BERT_phising_filter.pth')) # phishing filter\n","  phising_filter.eval()\n","\n","  Xtest = my_data.Message\n","  ytest = my_data.Category.values\n","\n","\n","\n","else:\n","\n","  # greek BERT for classification\n","  tokenizer = AutoTokenizer.from_pretrained(\"nlpaueb/bert-base-greek-uncased-v1\")\n","  social_prom_filter = AutoModelForSequenceClassification.from_pretrained(\"nlpaueb/bert-base-greek-uncased-v1\",num_labels=2).to(device)\n","  advertisement_filter = AutoModelForSequenceClassification.from_pretrained(\"nlpaueb/bert-base-greek-uncased-v1\",num_labels=2).to(device)\n","  phising_filter = AutoModelForSequenceClassification.from_pretrained(\"nlpaueb/bert-base-greek-uncased-v1\",num_labels=2).to(device)\n","\n","  # load the fine tuned thematic filters\n","  social_prom_filter.load_state_dict(torch.load('/content/drive/My Drive/spam_detection/thematic_filtering/Greek_BERT_social_promotion_filter.pth')) # social promotion filter\n","  social_prom_filter.eval()\n","  advertisement_filter.load_state_dict(torch.load('/content/drive/My Drive/spam_detection/thematic_filtering/Greek_BERT_advertisement_filter.pth')) # advertisement filter\n","  advertisement_filter.eval()\n","  phising_filter.load_state_dict(torch.load('/content/drive/My Drive/spam_detection/thematic_filtering/Greek_BERT_phising_filter.pth')) # phishing filter\n","  phising_filter.eval()\n","\n","  # Xtest = my_data.gtrans_el # machine translated\n","  Xtest = my_data.Message_el # human translated\n","  ytest = my_data.Category.values\n"],"metadata":{"id":"VShfOONRSIWc","executionInfo":{"status":"ok","timestamp":1700261908706,"user_tz":-120,"elapsed":9150,"user":{"displayName":"Basilis Sakellariou","userId":"01245548050423359889"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1e1c301d-4d8a-441d-9957-636fa514dbea"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlpaueb/bert-base-greek-uncased-v1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlpaueb/bert-base-greek-uncased-v1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlpaueb/bert-base-greek-uncased-v1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["def get_prob(logits):\n"," prob = F.softmax(logits,dim=1)\n"," return prob"],"metadata":{"id":"AiLstkltUq7P","executionInfo":{"status":"ok","timestamp":1700261908707,"user_tz":-120,"elapsed":5,"user":{"displayName":"Basilis Sakellariou","userId":"01245548050423359889"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["def encode_input(Xtest):\n","\n","  encoded_test = tokenizer.batch_encode_plus(Xtest.tolist(), add_special_tokens=True, max_length = 128, padding='max_length' , truncation=True, return_tensors = 'pt')\n","  input_ids_test = encoded_test['input_ids']\n","  attention_mask_test = encoded_test['attention_mask']\n","  labels_test = torch.tensor(ytest)\n","  data_test = TensorDataset(input_ids_test, attention_mask_test, labels_test)\n","  dataloader_test = DataLoader(\n","                data_test, # The validation samples.\n","                batch_size = 32, # Evaluate with this batch size.\n","                shuffle = False\n","            )\n","\n","  return dataloader_test"],"metadata":{"id":"RRw3LO-9VU_c","executionInfo":{"status":"ok","timestamp":1700261908707,"user_tz":-120,"elapsed":4,"user":{"displayName":"Basilis Sakellariou","userId":"01245548050423359889"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["dataloader_test = encode_input(Xtest)"],"metadata":{"id":"yP4qbXZpcHpm","executionInfo":{"status":"ok","timestamp":1700262014516,"user_tz":-120,"elapsed":1084,"user":{"displayName":"Basilis Sakellariou","userId":"01245548050423359889"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["models = [social_prom_filter, advertisement_filter, phising_filter]\n","prob = np.zeros((len(models),len(Xtest),2))\n","\n","for i in range(len(models)):\n","  all_logits = []\n","  for step,batch in enumerate(dataloader_test):\n","    input_ids = batch[0].to(device)\n","    attention_mask = batch[1].to(device)\n","    labels = batch[2].to(device)\n","    with torch.no_grad():\n","      outputs = models[i](input_ids, attention_mask=attention_mask, labels=labels)\n","    all_logits.append(outputs.logits.cpu())\n","  all_logits = torch.cat(all_logits, dim=0)\n","  prob[i,:,:] = get_prob(all_logits)\n"],"metadata":{"id":"dxYgBcB6Uzl1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# if a filter predict as spam a sample then we take it as spam\n","\n","# # # predictions based on models\n","pred1 = np.array(np.argmax(prob[0,:,:],axis=1)) # predictions based on social promotion filter\n","pred2 = np.array(np.argmax(prob[1,:,:],axis=1)) # predictions based on advertising filter\n","pred3 = np.array(np.argmax(prob[2,:,:],axis=1)) # predictions based on phishing filter\n","\n","final_pred = pred1 + pred2 + pred3\n","\n","final_pred = [1 if pred >= 1 else 0 for pred in final_pred]\n","\n","\n","print(\"Classification report on pipeline of filters:\\n\\n\"+str(classification_report(ytest,final_pred,target_names=['ham','spam'])))\n","print(\"accuracy is \"+str(round(accuracy_score(ytest,final_pred),4)))\n","print(\"balanced accuracy is \"+str(round(balanced_accuracy_score(ytest,final_pred),4)))\n","print(\"f1 macro is \"+str(round(f1_score(ytest,final_pred,average='macro'),4)))\n","print(\"confusion matrix\"+str(confusion_matrix(ytest, final_pred))+\"\\n\\n\") # [[TN FP],[FN TP]]"],"metadata":{"id":"8ax1aPfntqfF"},"execution_count":null,"outputs":[]}]}